# -*- coding: utf-8 -*-
"""Trading_Bot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dLB2i555iOIeDqeWd9qc1MRmFfsxIBDY
"""

# Import Statements
import yfinance as yf
import pandas as pd
import numpy as np
import xgboost as xgb
#!pip install ta
#!pip install TA-Lib
import ta
from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV
from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, precision_recall_curve
from sklearn.preprocessing import StandardScaler, RobustScaler
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from collections import Counter
import base64
import requests
from datetime import datetime

"""## Model 2"""

# Tickers
  # Concentrated momentum strategy
focused_watchlist = [
    "TSLA",
    "NVDA",
    "MSFT",
    "META",
    "AAPL",
    "AMZN",
    "PANW",
    "SHOP",
    "PLTR"
]
tickers = sorted(set(focused_watchlist))

# Configuration and Feature Engineering
LOOKBACK_WINDOW = 14
FORECAST_HORIZON = 1
MIN_PROBABILITY = 0.75

def compute_technical_indicators(df):
    df = df.copy()

    for col in ['Close', 'High', 'Low', 'Open', 'Volume']:
        if isinstance(df[col], pd.DataFrame):
            df[col] = df[col].iloc[:, 0]

    df['ma10'] = df['Close'].rolling(window=10).mean()
    df['ma20'] = df['Close'].rolling(window=20).mean()
    df['ma50'] = df['Close'].rolling(window=50).mean()
    df['ma200'] = df['Close'].rolling(window=200).mean()

    middle_band = df['Close'].rolling(window=20).mean()
    std_dev = df['Close'].rolling(window=20).std()
    df['middle_band'] = middle_band
    std_dev = std_dev.iloc[:,0]
    df['upper_band'] = df['middle_band'] + (std_dev * 2)
    df['lower_band'] = df['middle_band'] - (std_dev * 2)
    df['b_percent'] = (df['Close'].iloc[:,0] - df['lower_band']) / (df['upper_band'] - df['lower_band'])

    macd = ta.trend.MACD(df['Close'].iloc[:,0], window_slow=26, window_fast=12, window_sign=9)
    df['macd'] = macd.macd()
    df['macd_signal'] = macd.macd_signal()
    df['macd_diff'] = macd.macd_diff()

    df['rsi'] = ta.momentum.RSIIndicator(close=df['Close'].iloc[:,0], window=LOOKBACK_WINDOW).rsi()
    df['tsi'] = ta.momentum.TSIIndicator(close=df['Close'].iloc[:,0], window_slow=25, window_fast=13).tsi()

    stoch = ta.momentum.StochasticOscillator(high=df['High'].iloc[:,0], low=df['Low'].iloc[:,0], close=df['Close'].iloc[:,0], window=LOOKBACK_WINDOW)
    df['stoch_k'] = stoch.stoch()
    df['stoch_d'] = stoch.stoch_signal()

    df['volume_ma'] = df['Volume'].iloc[:,0].rolling(window=10).mean()
    df['obv'] = ta.volume.OnBalanceVolumeIndicator(close=df['Close'].iloc[:,0], volume=df['Volume'].iloc[:,0]).on_balance_volume()
    df['vwap'] = ta.volume.VolumeWeightedAveragePrice(high=df['High'].iloc[:,0], low=df['Low'].iloc[:,0], close=df['Close'].iloc[:,0], volume=df['Volume'].iloc[:,0]).volume_weighted_average_price()

    df['daily_return'] = df['Close'].iloc[:,0].pct_change()
    df['close_ratio'] = (df['Close'].iloc[:,0] - df['Open'].iloc[:,0]) / (df['High'].iloc[:,0] - df['Low'].iloc[:,0] + 1e-10)
    df['volatility'] = df['daily_return'].rolling(window=LOOKBACK_WINDOW).std()
    df['atr'] = ta.volatility.AverageTrueRange(high=df['High'].iloc[:,0], low=df['Low'].iloc[:,0], close=df['Close'].iloc[:,0], window=14).average_true_range()

    df['price_trend'] = df['Close'].iloc[:,0].rolling(window=5).mean() / df['Close'].iloc[:,0].rolling(window=20).mean()
    df['volume_trend'] = df['Volume'].iloc[:,0].rolling(window=5).mean() / df['Volume'].iloc[:,0].rolling(window=20).mean()
    df['adx'] = ta.trend.ADXIndicator(high=df['High'].iloc[:,0], low=df['Low'].iloc[:,0], close=df['Close'].iloc[:,0], window=14).adx()

    return df

def get_stock_data_enhanced(ticker):
    df = yf.download(ticker, start="2021-01-01", end=datetime.today().strftime('%Y-%m-%d'), auto_adjust=True)
    df = df[['Open', 'High', 'Low', 'Close', 'Volume']].copy()

    df = compute_technical_indicators(df)

    for horizon in [1, 3, 5]:
        df[f'Future_Close_{horizon}'] = df['Close'].iloc[:,0].shift(-horizon)
        df[f'Return_{horizon}'] = (df[f'Future_Close_{horizon}'] - df['Close'].iloc[:,0]) / df['Close'].iloc[:,0]
        df[f'Signal_{horizon}'] = (df[f'Return_{horizon}'] > 0).astype(int)

    df['Ticker'] = ticker
    df.dropna(inplace=True)

    return df

# Modeling
def create_ensemble_model(scale_pos_weight=1):
    xgb_model = xgb.XGBClassifier(
        n_estimators=300,
        max_depth=6,
        learning_rate=0.03,
        subsample=0.75,
        colsample_bytree=0.75,
        gamma=0.2,
        reg_alpha=0.2,
        reg_lambda=1.0,
        random_state=42,
        eval_metric='logloss'
    )
    lr_model = LogisticRegression(
        penalty='l2',
        C=1.0,
        solver='liblinear',
        random_state=42,
        max_iter=1000,
        class_weight='balanced'
    )
    svm_model = SVC(
        C=1.0,
        kernel='rbf',
        probability=True,
        random_state=42,
        class_weight='balanced'
    )
    ensemble = VotingClassifier(
        estimators=[
            ('xgb', xgb_model),
            ('lr', lr_model),
            ('svm', svm_model)
        ],
        voting='soft',
        weights=[3, 1, 1]
    )

    return ensemble

def train_and_predict_enhanced(ticker, df):
    # features = ['ma10', 'ma20', 'ma50', 'ma200',
    #             'upper_band', 'middle_band', 'lower_band', 'b_percent',
    #             'macd', 'macd_signal', 'macd_diff',
    #             'rsi', 'tsi', 'stoch_k', 'stoch_d',
    #             'volume_ma', 'obv', 'vwap',
    #             'daily_return', 'close_ratio', 'volatility', 'atr',
    #             'price_trend', 'volume_trend', 'adx',
    #             'engulfing', 'hammer'
    #           ]

    features = ['vwap', 'obv', 'stoch_k',
                'ma10', 'ma50', 'ma200',
                'atr', 'rsi', 'adx',
                'daily_return'
               ]

    target = 'Signal_1'
    X = df[features]
    y = df[target]

    train_size = int(0.7 * len(X))
    X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]
    y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]

    neg, pos = np.bincount(y_train)
    scale_pos_weight = neg / pos if pos > 0 else 1

    scaler = RobustScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    model = create_ensemble_model()
    model.fit(X_train_scaled, y_train)

    y_proba_test = model.predict_proba(X_test_scaled)[:, 1]
    precision, recall, thresholds = precision_recall_curve(y_test, y_proba_test)
    f1_scores = np.where((precision + recall) > 0, 2 * precision * recall / (precision + recall), 0)
    best_threshold = thresholds[np.argmax(f1_scores)]

    X_full_scaled = scaler.transform(X)
    df['PredictedProb'] = model.predict_proba(X_full_scaled)[:, 1]
    df['PredictedSignal'] = (df['PredictedProb'] > best_threshold).astype(int)

    print(f"\nFinal Performance for {ticker}:")
    print(f"Best Threshold: {best_threshold:.4f}")
    print(classification_report(y, df['PredictedSignal']))
    print(f"F1 Score: {f1_score(y, df['PredictedSignal']):.4f}")
    print(f"Precision: {precision_score(y, df['PredictedSignal']):.4f}")
    print(f"Recall: {recall_score(y, df['PredictedSignal']):.4f}")

    xgb_importance = pd.DataFrame({
        'Feature': features,
        'Importance': model.named_estimators_['xgb'].feature_importances_
    }).sort_values('Importance', ascending=False)
    print(f"\nFeature importance for {ticker}:")
    print(xgb_importance.head(10))

    df['Ticker'] = ticker
    df['Volatility'] = df['volatility']

    return df[['Ticker', 'PredictedSignal', 'PredictedProb', 'Volatility']].copy()

# Predict / Main Execution
all_predictions = []
f1_results = []

for ticker in tickers:
    try:
        df = get_stock_data_enhanced(ticker)
        pred_df = train_and_predict_enhanced(ticker, df)
        pred_df.index = df.index

        pred_df['PositionSize'] = np.where(
            pred_df['PredictedProb'] > MIN_PROBABILITY,
            pred_df['PredictedProb'] * 0.75,
            0
        )
        all_predictions.append(pred_df)
        f1 = f1_score(df['Signal_1'], pred_df['PredictedSignal'])
        f1_results.append({'Ticker': ticker, 'F1': f1})

    except Exception as e:
        print(f"Error with {ticker}: {e}")

combined_df = pd.concat(all_predictions).sort_index()
combined_df.index.name = 'Date'

combined_df['FinalSignal'] = np.where(combined_df['PredictedProb'] > MIN_PROBABILITY, combined_df['PredictedSignal'], 0)

# Pushing to Github
combined_df_cleaned = combined_df.reset_index()
combined_df_cleaned = combined_df_cleaned[['Date', 'Ticker', 'PredictedSignal', 'PredictedProb', 'Volatility']]
combined_df_cleaned['Date'] = pd.to_datetime(combined_df_cleaned['Date']).dt.strftime('%-m/%-d/%Y')
combined_df_cleaned = combined_df_cleaned.dropna(how='all')
combined_df_cleaned.to_csv("stock_signals.csv", index=False)

TOKEN = "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"
REPO = "nolknies/temp"
FILEPATH = "stock_signals.csv"
GITHUB_FILEPATH = "stock_signals.csv"
COMMIT_MESSAGE = "Upload latest trading signals"
BRANCH = "main"

with open(FILEPATH, "rb") as f:
    content = f.read()
    content_b64 = base64.b64encode(content).decode("utf-8")

url = f"https://api.github.com/repos/{REPO}/contents/{GITHUB_FILEPATH}"
headers = {"Authorization": f"token {TOKEN}"}
res = requests.get(url, headers=headers)
sha = res.json().get("sha") if res.status_code == 200 else None

payload = {
    "message": COMMIT_MESSAGE,
    "content": content_b64,
    "branch": BRANCH,
}
if sha:
    payload["sha"] = sha

put_res = requests.put(url, headers=headers, json=payload)

if put_res.status_code in [200, 201]:
    print("✅ File uploaded successfully!")
else:
    print("❌ Upload failed:", put_res.status_code, put_res.json())
